{
 "metadata": {
  "name": "",
  "signature": "sha256:dc6e1cbcec05f3c8b096c554a8e615d3e98a5a63db353b3f0b0a9f30aa4f4f48"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Sparse Grid Clique Fitting on Million Song Dataset"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The notebook illustrates how fitting with cliques works on the million song dataset. The code only uses grid evaluation routines form SG++ and relies on the numerical routines from scipy to avoid a potential point of failure"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "# IMPORTANT: I import the pathes manually, as I have many differnt SG++ branches instaled\n",
      "# but you may have them from your system environment already\n",
      "del sys.path[2]\n",
      "sys.path.append('/home/perun/Documents/workspace/SGpp.trunk')\n",
      "sys.path.append('/home/perun/Documents/workspace/SGpp.trunk/bin')\n",
      "\n",
      "import pysgpp as ps\n",
      "import numpy as np\n",
      "import scipy as sp\n",
      "import scipy.sparse.linalg\n",
      "import arff\n",
      "import learner.LearnerBuilder as LearnerBuilder"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Read Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filename = 'datasets/input/regression/million_songs_200000.arff'\n",
      "data_arff = arff.load(filename)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rows = 200000\n",
      "dim = 90\n",
      "subset_size = 1000\n",
      "data = np.empty((rows, dim), dtype=np.float32)\n",
      "targets = np.empty(rows, dtype=np.float32)\n",
      "i = 0\n",
      "for row in data_arff:\n",
      "    data[i,:] = row._values[1:(dim+1)]\n",
      "    targets[i] = row._values[0]\n",
      "    i += 1\n",
      "    if i == rows: break\n",
      "random_indices = np.random.permutation(xrange(rows))[:subset_size]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I select 10000 random rows from the dataset to avoid sorting of the rows.\n",
      "\n",
      "*IMPORTANT:* you need to normalise your dataset!!!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_norm = data\n",
      "for d in xrange(data_norm.shape[1]):\n",
      "    m = np.min(data_norm[:, d])\n",
      "    M = np.max(data_norm[:, d])\n",
      "    data_norm[:, d] = (data_norm[:, d]-m)/(M-m)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 53
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Using SciPy Numerical Routines"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class CliqueLearner(object):\n",
      "    def __init__(self, clique_size, components_grid, level):\n",
      "        \"\"\"Constructor\n",
      "        :param clique_size: number of dimensions in one clique\n",
      "        :param components_grid: number of components (cliques) in the grid\n",
      "        :param level: maxim level fo the grid\n",
      "        \"\"\"\n",
      "        self.clique_size = 3\n",
      "        self.components_grid = 4\n",
      "        self.level = 3\n",
      "        self.dim_grid = clique_size*components_grid #totoal grid dimensions\n",
      "        \n",
      "        # create grid\n",
      "        self.grid = ps.Grid.createModLinearGrid(self.dim_grid)\n",
      "        self.grid.createGridGenerator().cliques(self.level, self.clique_size)\n",
      "        \n",
      "        self.B = None #evaluation matrix\n",
      "        self.A = None #symmetric system matrix for CG\n",
      "        self.opEval = None #operation Multiple Eval\n",
      "        \n",
      "        \n",
      "    def get_grid_dim(self):\n",
      "        \"\"\"Return total grid dimensions\"\"\"\n",
      "        return self.dim_grid\n",
      "\n",
      "    \n",
      "    \n",
      "def get_system_matrix(grid_size, data_size, opEval, damp):\n",
      "    \"\"\"Computes scipy LinearOperator corresponding to (B^TB + \\lambda I) in sparse grid literature\n",
      "    :param data: ndarra with input data\n",
      "    :param damp: float damping parameter (regression parameter \\lambda)\n",
      "    \"\"\"\n",
      "\n",
      "    def matvec_sym(x, data_size, grid_size):\n",
      "        x_dv = ps.DataVector(x)\n",
      "        result = ps.DataVector(data_size)\n",
      "        opEval.mult(x_dv, result)\n",
      "        opEval.multTranspose(result, x_dv)\n",
      "        return x_dv.array() + damp*x\n",
      "    A = sp.sparse.linalg.LinearOperator((grid_size, grid_size), \n",
      "                                        matvec=lambda x: matvec_sym(x, data_size, grid_size), \n",
      "                                        dtype=np.float32)\n",
      "    return A\n",
      "        \n",
      "    \n",
      "def get_evaluation_matrix(grid_size, data_size, opEval):\n",
      "    \"\"\"Return the scipy LinearOperator that acts as the matrix B from sparse grids literature.\n",
      "    :param dataset: ndarray with input data\n",
      "    \"\"\"\n",
      "    def matvec(x, size, opEval):\n",
      "        \"\"\"computes Bx\"\"\"\n",
      "        x_dv = ps.DataVector(x)\n",
      "        result = ps.DataVector(size)\n",
      "        opEval.mult(x_dv, result)\n",
      "        return result.array()\n",
      "\n",
      "    def rmatvec(x, size, opEval):\n",
      "        \"\"\"computes B^T x\"\"\"\n",
      "        x_dv = ps.DataVector(x)\n",
      "        result = ps.DataVector(size)\n",
      "        opEval.multTranspose(x_dv, result)\n",
      "        return result.array()\n",
      "    mv = lambda x: matvec(x, data_size, opEval)\n",
      "    rmv = lambda x: rmatvec(x, grid_size, opEval)\n",
      "    # see scipy documentation for details\n",
      "    # http://docs.scipy.org/doc/scipy/reference/sparse.linalg.html\n",
      "    B = sp.sparse.linalg.LinearOperator((data_size, grid_size), \n",
      "                                             matvec=mv, rmatvec=rmv, dtype=np.float32)\n",
      "    return B"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clique_size = 3\n",
      "level = 3\n",
      "damping = 1E-6\n",
      "\n",
      "for components_grid in xrange(1, 6):\n",
      "    clique_learner = CliqueLearner(clique_size, components_grid, level)\n",
      "    dim_grid = clique_learner.get_grid_dim()\n",
      "\n",
      "    # get random subset for training. First dim_grid features selected, no randomisation\n",
      "    data_subset = data_norm[random_indices, 25:(25+dim_grid)]\n",
      "    targets_subset = targets[random_indices]\n",
      "    #create linear opeartors and rhs\n",
      "    dataset_dm = ps.DataMatrix(data_subset)\n",
      "    opEval = ps.createOperationMultipleEval(clique_learner.grid, dataset_dm)\n",
      "    B = get_evaluation_matrix(clique_learner.grid.getSize(), data_subset.shape[0], opEval)\n",
      "    A = get_system_matrix(clique_learner.grid.getSize(), data_subset.shape[0], opEval, damping)\n",
      "    #rhs\n",
      "    b = B.rmatvec(targets_subset)\n",
      "    print \"solving system...\"\n",
      "    \n",
      "    def increment():\n",
      "        increment.counter += 1\n",
      "    increment.counter = 0\n",
      "    cg_callback = lambda x: increment()\n",
      "    x = sp.sparse.linalg.cg(A, b, maxiter = 500, tol=1e-8, callback=cg_callback)\n",
      "    print \"num comp:\", components_grid, \"grid size:\", clique_learner.grid.getSize(),\\\n",
      "    \"CG iterations\", increment.counter, \"residual\",np.linalg.norm(b- A.dot(x[0])),\\\n",
      "    \"error\", np.linalg.norm(targets_subset- B.dot(x[0]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "solving system...\n",
        "num comp:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1 grid size: 31 CG iterations 44 residual "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.173380907053 error 1080.17985433\n",
        "solving system..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "num comp:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2 grid size: 61 CG iterations 102 residual "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.378420958842 error "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1072.34873198\n",
        "solving system..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "num comp:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3 grid size: 91 CG iterations 149 residual "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.444670934554 error "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1070.47340417\n",
        "solving system..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "num comp:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4 grid size: 121 CG iterations 366 residual "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.619994918002 error "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1059.7849684\n",
        "solving system..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "num comp:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5 grid size: 151 CG iterations 500 residual "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "4.04544038361 error "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1045.77464557\n"
       ]
      }
     ],
     "prompt_number": 75
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As you can see, the error continuesly fall, es expected."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Using SG++ Python Interface"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import bin.learner.LearnerBuilder as LearnerBuilder\n",
      "import bin.learner.Types as Types\n",
      "\n",
      "clique_size = 3\n",
      "level = 3\n",
      "damping = 1E-6\n",
      "\n",
      "for components_grid in xrange(1,6):\n",
      "    dim_grid = components_grid*clique_size\n",
      "    data_subset = data_norm[random_indices, :dim_grid]\n",
      "    targets_subset = targets[random_indices]\n",
      "    \n",
      "    builder = LearnerBuilder()\n",
      "    builder = LearnerBuilder()\n",
      "    builder = builder.buildRegressor()\n",
      "    builder = builder.withTrainingDataFromNumPyArray(data_subset,targets_subset)\n",
      "    builder = builder.withGrid().withLevel(level).withCliques(clique_size).withBorder(Types.BorderTypes.NONE)\n",
      "    builder = builder.withSpecification().withLambda(damping).withAdaptPoints(0)\\\n",
      "                         .withStopPolicy().withAdaptiveItarationLimit(0)\\\n",
      "                         .withCGSolver().withImax(500).withAccuracy(1e-8)\n",
      "    learner = builder.andGetResult() \n",
      "    learner.learnData()\n",
      "    print \"num comp:\", components_grid, \"grid size:\", learner.grid.getSize(),\\\n",
      "    \"CG iterations\", learner.solver.getNumberIterations(), \"error\", np.sqrt(learner.trainingOverall[0]*subset_size)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "num comp: 1 grid size: 31 CG iterations 55 error 310.957720711\n",
        "num comp:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2 grid size: 61 CG iterations 173 error 303.780847412\n",
        "num comp:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3 grid size: 91 CG iterations 361 error 299.101471297\n",
        "num comp:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4 grid size: 121 CG iterations 449 error 291.903788845\n",
        "num comp:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5 grid size: 151 CG iterations 500 error 283.535823667\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this case I took only 1000 points instead of 10000 as before. You can see, the results are similar."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}